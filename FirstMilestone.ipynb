{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as web    #to get the stock prices\n",
    "from datetime import datetime\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5332.000000</td>\n",
       "      <td>5332.000000</td>\n",
       "      <td>5332.000000</td>\n",
       "      <td>5332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.731317</td>\n",
       "      <td>19.728394</td>\n",
       "      <td>19.508618</td>\n",
       "      <td>19.939620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.956312</td>\n",
       "      <td>25.960731</td>\n",
       "      <td>25.622978</td>\n",
       "      <td>26.269164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.234286</td>\n",
       "      <td>0.231964</td>\n",
       "      <td>0.227143</td>\n",
       "      <td>0.235536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.396831</td>\n",
       "      <td>1.391607</td>\n",
       "      <td>1.377500</td>\n",
       "      <td>1.416652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.356607</td>\n",
       "      <td>9.391250</td>\n",
       "      <td>9.283393</td>\n",
       "      <td>9.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.013750</td>\n",
       "      <td>28.005624</td>\n",
       "      <td>27.666251</td>\n",
       "      <td>28.258750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>143.160004</td>\n",
       "      <td>143.600006</td>\n",
       "      <td>141.369995</td>\n",
       "      <td>145.089996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Close         Open          Low         High\n",
       "count  5332.000000  5332.000000  5332.000000  5332.000000\n",
       "mean     19.731317    19.728394    19.508618    19.939620\n",
       "std      25.956312    25.960731    25.622978    26.269164\n",
       "min       0.234286     0.231964     0.227143     0.235536\n",
       "25%       1.396831     1.391607     1.377500     1.416652\n",
       "50%       9.356607     9.391250     9.283393     9.457143\n",
       "75%      28.013750    28.005624    27.666251    28.258750\n",
       "max     143.160004   143.600006   141.369995   145.089996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime(2000, 1, 1)\n",
    "end = datetime.now()\n",
    "\n",
    "df = web.DataReader(\"AAPL\", 'yahoo', start, end)\n",
    "df = df.reset_index()\n",
    "df = df[['Date', 'Close','Open','Low','High']]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>1.004464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>0.987723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.987165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.955357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>0.901786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>2012-09-12</td>\n",
       "      <td>23.921070</td>\n",
       "      <td>23.816071</td>\n",
       "      <td>23.428572</td>\n",
       "      <td>23.924999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>24.392143</td>\n",
       "      <td>24.191786</td>\n",
       "      <td>24.098928</td>\n",
       "      <td>24.482143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>2012-09-14</td>\n",
       "      <td>24.688572</td>\n",
       "      <td>24.641430</td>\n",
       "      <td>24.567499</td>\n",
       "      <td>24.892143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>24.992144</td>\n",
       "      <td>24.976786</td>\n",
       "      <td>24.807501</td>\n",
       "      <td>24.992857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>2012-09-18</td>\n",
       "      <td>25.068214</td>\n",
       "      <td>24.995714</td>\n",
       "      <td>24.872143</td>\n",
       "      <td>25.083214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3199 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Close       Open        Low       High\n",
       "0    2000-01-03   0.999442   0.936384   0.907924   1.004464\n",
       "1    2000-01-04   0.915179   0.966518   0.903460   0.987723\n",
       "2    2000-01-05   0.928571   0.926339   0.919643   0.987165\n",
       "3    2000-01-06   0.848214   0.947545   0.848214   0.955357\n",
       "4    2000-01-07   0.888393   0.861607   0.852679   0.901786\n",
       "...         ...        ...        ...        ...        ...\n",
       "3194 2012-09-12  23.921070  23.816071  23.428572  23.924999\n",
       "3195 2012-09-13  24.392143  24.191786  24.098928  24.482143\n",
       "3196 2012-09-14  24.688572  24.641430  24.567499  24.892143\n",
       "3197 2012-09-17  24.992144  24.976786  24.807501  24.992857\n",
       "3198 2012-09-18  25.068214  24.995714  24.872143  25.083214\n",
       "\n",
       "[3199 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = int(df.shape[0]*0.6)\n",
    "train_set = df.head(index)\n",
    "dataClosed = train_set.iloc[:, 1:2].values\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3199"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "dataClosedScaled = sc.fit_transform(dataClosed)\n",
    "len(dataClosedScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3139"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(dataClosedScaled)):\n",
    "    x_train.append(dataClosedScaled[i-60:i, 0])\n",
    "    y_train.append(dataClosedScaled[i, 0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense        \n",
    "from keras.layers import LSTM        \n",
    "from keras.layers import Dropout      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.0365\n",
      "Epoch 2/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 6.3252e-04\n",
      "Epoch 3/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 5.9085e-04\n",
      "Epoch 4/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 5.4339e-04\n",
      "Epoch 5/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 5.5918e-04\n",
      "Epoch 6/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 5.1703e-04\n",
      "Epoch 7/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 4.6990e-04\n",
      "Epoch 8/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 5.5045e-04\n",
      "Epoch 9/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 7.7981e-04\n",
      "Epoch 10/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 5.7067e-04\n",
      "Epoch 11/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.8297e-04\n",
      "Epoch 12/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 4.0682e-04\n",
      "Epoch 13/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 4.1229e-04\n",
      "Epoch 14/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.9666e-04\n",
      "Epoch 15/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.8316e-04\n",
      "Epoch 16/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 4.1688e-04\n",
      "Epoch 17/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.8290e-04\n",
      "Epoch 18/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 4.9083e-04\n",
      "Epoch 19/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.1792e-04\n",
      "Epoch 20/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 4.7733e-04\n",
      "Epoch 21/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.2866e-04\n",
      "Epoch 22/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 6.6477e-04\n",
      "Epoch 23/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.7364e-04\n",
      "Epoch 24/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.4660e-04\n",
      "Epoch 25/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.1887e-04\n",
      "Epoch 26/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.3990e-04\n",
      "Epoch 27/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.2355e-04\n",
      "Epoch 28/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.9953e-04\n",
      "Epoch 29/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.5385e-04\n",
      "Epoch 30/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.1855e-04\n",
      "Epoch 31/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 2.7135e-04\n",
      "Epoch 32/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.0196e-04\n",
      "Epoch 33/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.9002e-04\n",
      "Epoch 34/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 2.9906e-04\n",
      "Epoch 35/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 3.1056e-04\n",
      "Epoch 36/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.9936e-04\n",
      "Epoch 37/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.4431e-04\n",
      "Epoch 38/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 8.4469e-04\n",
      "Epoch 39/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.8719e-04\n",
      "Epoch 40/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.8523e-04\n",
      "Epoch 41/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.2433e-04\n",
      "Epoch 42/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 9.6579e-04\n",
      "Epoch 43/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.7194e-04\n",
      "Epoch 44/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.8920e-04\n",
      "Epoch 45/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.0117e-04\n",
      "Epoch 46/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.9874e-04\n",
      "Epoch 47/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.1378e-04\n",
      "Epoch 48/75\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 2.4003e-04\n",
      "Epoch 49/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 3.6986e-04\n",
      "Epoch 50/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.9722e-04\n",
      "Epoch 51/75\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 2.2132e-04\n",
      "Epoch 52/75\n",
      "31/50 [=================>............] - ETA: 0s - loss: 2.7675e-04"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( LSTM (units = 512, return_sequences = True , input_shape = ( x_train.shape[1],1 ) ,recurrent_activation='sigmoid') )\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add( LSTM (units = 256, return_sequences = True ) )\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add( LSTM (units = 128, return_sequences = True ) )\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add( LSTM (units = 512) )\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 75, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['loss']\n",
    "plt.plot(loss_train, 'g', label='Training loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mean = np.mean(loss_train)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df.tail(df.shape[0]-index)\n",
    "real_values = test_set.iloc[:, 1:2].values\n",
    "\n",
    "total_data = pd.concat(( train_set['Close'],test_set['Close']), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = total_data[len(total_data)-len(test_set)-60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(60,len(real_values)):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "predictions = model.predict(X_test)\n",
    "predictions = sc.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,19))\n",
    "plt.plot(real_values, color = 'black', label = 'Apple Stock Price')\n",
    "plt.plot(predictions, color = 'green', label = 'Predicted Apple Stock Price')\n",
    "plt.xticks(range(0,len(real_values),200),df['Date'].loc[::500],rotation=45)\n",
    "plt.title('Apple Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Apple Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
